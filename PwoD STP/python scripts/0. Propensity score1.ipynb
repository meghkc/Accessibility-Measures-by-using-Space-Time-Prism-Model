{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Load the datasets\n",
    "control_group_df = pd.read_csv(fr\"E:\\Propensity score matching analysis\\TAZ_destination.csv\")\n",
    "treatment_group_df = pd.read_csv(fr\"E:\\STP_PWoD\\Data\\TAZ_destination_PwoD.csv\")\n",
    "print('persons in control group:', control_group_df['hhmemberid'].nunique())\n",
    "print('persons in treatment group:', treatment_group_df['hhmemberid'].nunique())\n",
    "\n",
    "# counting number of trips in each of the counties CO_NAME\n",
    "value_counts = control_group_df['CO_NAME'].value_counts()\n",
    "for name, count in value_counts.items():\n",
    "    print(f\"{name}: {count}\")\n",
    "\n",
    "# Selecting relevant columns\n",
    "relevant_columns = ['age', 'gender', 'education','licensed','num_veh','workers','hhsize','emp_text','CO_NAME'] # 'hh_income'\n",
    "# Print unique values in each column for both groups\n",
    "print(\"Unique values in Control Group:\")\n",
    "for col in relevant_columns:\n",
    "    print(f\"{col}: {control_group_df[col].unique()}\")\n",
    "\n",
    "print(\"\\nUnique values in Treatment Group:\")\n",
    "for col in relevant_columns:\n",
    "    print(f\"{col}: {treatment_group_df[col].unique()}\")\n",
    "\n",
    "# Unique values in control_group_df\n",
    "control_emp_values = control_group_df['emp_text'].unique()\n",
    "# Filtering treatment_group_df to have only those values in control_emp_values\n",
    "treatment_group_df = treatment_group_df[treatment_group_df['emp_text'].isin(control_emp_values)]\n",
    "\n",
    "# Unique counties values in control_group_df\n",
    "control_county_values = control_group_df['CO_NAME'].unique()\n",
    "# Filtering treatment_group_df to have only those values in control_county_values\n",
    "treatment_group_df = treatment_group_df[treatment_group_df['CO_NAME'].isin(control_county_values)]\n",
    "\n",
    "# # Filter out rows where 'hh_income' is -1 in both datasets\n",
    "# control_group_df = control_group_df[control_group_df['hh_income'] != -1]\n",
    "# treatment_group_df = treatment_group_df[treatment_group_df['hh_income'] != -1]\n",
    "\n",
    "control_group_df = control_group_df[relevant_columns]\n",
    "treatment_group_df = treatment_group_df[relevant_columns]\n",
    "\n",
    "# Encoding categorical variables if necessary\n",
    "le = LabelEncoder()\n",
    "if control_group_df['gender'].dtype == object:\n",
    "    control_group_df['gender'] = le.fit_transform(control_group_df['gender'])\n",
    "    treatment_group_df['gender'] = le.transform(treatment_group_df['gender'])\n",
    "if control_group_df['education'].dtype == object:\n",
    "    control_group_df['education'] = le.fit_transform(control_group_df['education'])\n",
    "    treatment_group_df['education'] = le.transform(treatment_group_df['education'])\n",
    "if control_group_df['emp_text'].dtype == object:\n",
    "    control_group_df['emp_text'] = le.fit_transform(control_group_df['emp_text'])\n",
    "    treatment_group_df['emp_text'] = le.transform(treatment_group_df['emp_text'])\n",
    "if control_group_df['licensed'].dtype == object:\n",
    "    control_group_df['licensed'] = le.fit_transform(control_group_df['licensed'])\n",
    "    treatment_group_df['licensed'] = le.transform(treatment_group_df['licensed'])\n",
    "if control_group_df['age'].dtype == object:\n",
    "    control_group_df['age'] = le.fit_transform(control_group_df['age'])\n",
    "    treatment_group_df['age'] = le.transform(treatment_group_df['age'])\n",
    "if control_group_df['CO_NAME'].dtype == object:\n",
    "    control_group_df['CO_NAME'] = le.fit_transform(control_group_df['CO_NAME'])\n",
    "    treatment_group_df['CO_NAME'] = le.transform(treatment_group_df['CO_NAME'])\n",
    "    \n",
    "# Preparing the data for propensity score estimation\n",
    "combined_df = pd.concat([treatment_group_df.assign(group=1), control_group_df.assign(group=0)])\n",
    "combined_df\n",
    "X = combined_df[relevant_columns]\n",
    "X \n",
    "\n",
    "y = combined_df['group']\n",
    "y\n",
    "\n",
    "# Checking the balance before matching\n",
    "print(\"Mean values of covariates before matching:\")\n",
    "print(combined_df.groupby('group').mean())\n",
    "\n",
    "def calculate_standardized_difference(df1, df2, covariates):\n",
    "    results = []\n",
    "    for covariate in covariates:\n",
    "        mean1 = df1[covariate].mean()\n",
    "        mean2 = df2[covariate].mean()\n",
    "        std1 = df1[covariate].std()\n",
    "        std2 = df2[covariate].std()\n",
    "        pooled_std = ((std1**2 + std2**2) / 2)**0.5\n",
    "        std_diff = (mean1 - mean2) / pooled_std\n",
    "        results.append({'Covariate': covariate, 'Standardized Difference': std_diff})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# # Assuming you have two dataframes df1 and df2, and a list of covariates\n",
    "# covariates = relevant_columns\n",
    "# standardized_differences = calculate_standardized_difference(control_group_df, treatment_group_df, covariates)\n",
    "# print('****************************************')\n",
    "# print('Before matching standardized_differences',standardized_differences)\n",
    "# print('****************************************')\n",
    "\n",
    "# Logistic regression model for propensity score\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X, y)\n",
    "combined_df['propensity_score'] = log_reg_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Separating the treatment and control groups\n",
    "treatment_df = combined_df[combined_df['group'] == 1]\n",
    "control_df = combined_df[combined_df['group'] == 0]\n",
    "\n",
    "# Relaxed criteria for matching\n",
    "caliper = 0.50 * combined_df['propensity_score'].std()\n",
    "expanded_matches = []\n",
    "for index, control_row in control_df.iterrows():\n",
    "    control_score = control_row['propensity_score']\n",
    "    potential_matches = treatment_df[(treatment_df['propensity_score'] >= control_score - caliper) &\n",
    "                                     (treatment_df['propensity_score'] <= control_score + caliper)]\n",
    "    selected_matches = potential_matches.sample(n=min(5, len(potential_matches)), replace=True, random_state=index)\n",
    "    expanded_matches.extend(selected_matches.values.tolist())\n",
    "\n",
    "expanded_matched_treatment_df = pd.DataFrame(expanded_matches, columns=treatment_df.columns)\n",
    "\n",
    "# Combining matched treatment and control groups for balance check\n",
    "matched_df = pd.concat([expanded_matched_treatment_df, control_df])\n",
    "\n",
    "# Checking the balance: compare the mean of the covariates in the matched groups\n",
    "balance_check = matched_df.groupby('group').mean()\n",
    "print(balance_check)\n",
    "\n",
    "# Resulting dataset size\n",
    "print(\"Size of Expanded Treatment Group:\", len(expanded_matched_treatment_df))\n",
    "print(\"Size of Control Group:\", len(control_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the original indices from the treatment dataset were preserved in the propensity score matching process\n",
    "\n",
    "# Reading the original treatment dataset again (for full columns)\n",
    "original_treatment_df = pd.read_csv(fr\"E:\\STP_PWoD\\Data\\TAZ_destination_PwoD.csv\")\n",
    "\n",
    "# Mapping the expanded matched treatment data to the original treatment data\n",
    "# Using the indices from the expanded_matched_treatment_df to retrieve the corresponding rows\n",
    "full_data_matched_treatment_df = original_treatment_df.iloc[expanded_matched_treatment_df.index]\n",
    "\n",
    "# Saving the full data matched treatment DataFrame as a CSV file\n",
    "full_data_matched_treatment_df.to_csv(fr\"E:\\STP_PWoD\\Data\\TAZ_destination_PwoD_PSM1.csv\", index=False)\n",
    "print('persons in treatment group:', full_data_matched_treatment_df['hhmemberid'].nunique())\n",
    "full_data_matched_treatment_df.head()  # Displaying the first few rows for verification\n",
    "\n",
    "# standardized_differences_aftermatch = calculate_standardized_difference(control_group_df, full_data_matched_treatment_df, covariates)\n",
    "# print('****************************************')\n",
    "# print('After matching standardized_differences',standardized_differences_aftermatch)\n",
    "# print('****************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = full_data_matched_treatment_df['CO_NAME'].value_counts()\n",
    "\n",
    "for name, count in value_counts.items():\n",
    "    print(f\"{name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping only matching hptripids in origin and destination dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "TAZ_origin_df = pd.read_csv(rf'E:\\Propensity score matching analysis\\TAZ_origin_PwoD_PSM.csv')\n",
    "TAZ_destination_df = pd.read_csv(rf'E:\\Propensity score matching analysis\\TAZ_destination_PwoD_PSM.csv')\n",
    "\n",
    "# Finding unique hptripid in each file\n",
    "unique_origin = set(TAZ_origin_df['hptripid'].unique())\n",
    "unique_destination = set(TAZ_destination_df['hptripid'].unique())\n",
    "# Common hptripid in both files\n",
    "common_hptripid = unique_origin.intersection(unique_destination)\n",
    "num_common_hptripid = len(common_hptripid)\n",
    "\n",
    "# Keeping only common hptripid in both files\n",
    "TAZ_origin_common = TAZ_origin_df[TAZ_origin_df['hptripid'].isin(common_hptripid)]\n",
    "TAZ_destination_common = TAZ_destination_df[TAZ_destination_df['hptripid'].isin(common_hptripid)]\n",
    "# Saving the matching hptripd origin and destination dataset data as a CSV file\n",
    "TAZ_origin_common.to_csv('TAZ_origin_PwoD_PSM1.csv', index=False)\n",
    "TAZ_destination_common.to_csv('TAZ_destination_PwoD_PSM1.csv', index=False)\n",
    "# Print the results\n",
    "print(\"Number of common hptripid in both files:\", num_common_hptripid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
